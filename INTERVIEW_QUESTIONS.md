# 면접 예상 질문 및 답변 가이드

> **작성일**: 2025-10-27
> **작성자**: 조민혁
> **이메일**: cmhblue1225@naver.com
> **전화번호**: 010-5116-5305

---

## 📌 목차

1. [자기소개](#자기소개)
2. [프로젝트별 예상 질문](#프로젝트별-예상-질문)
   - [Sensor Game Hub](#1-sensor-game-hub---센서-게임-플랫폼)
   - [Synapse AI](#2-synapse-ai---지능형-지식-관리-시스템)
   - [Convi](#3-convi---편의점-종합-솔루션)
   - [한 숨의 위로](#4-한-숨의-위로---감정-ai-상담-서비스)
   - [독독 (DockDock)](#5-독독-dockdock---독서-관리-플랫폼)
   - [Trading Intelligence](#6-trading-intelligence---ai-트레이딩-플랫폼)
   - [ReviseAI](#7-reviseai---ai-코드-리뷰-도구)
   - [AI Doc Generator](#8-ai-doc-generator---문서-자동-생성)
3. [공통 면접 질문](#공통-면접-질문)
4. [STAR 기법 답변 예시](#star-기법-답변-예시)

---

## 자기소개

### 1분 버전 (간단)

안녕하세요, 조민혁입니다. 저는 AI와 웹 풀스택 개발에 집중하며, 최신 기술을 활용해 사용자에게 실질적인 가치를 제공하는 서비스를 만들어왔습니다.

React 19, TypeScript, Supabase 등의 최신 기술 스택을 활용한 엔터프라이즈급 애플리케이션 개발과 OpenAI, Anthropic API를 활용한 AI 서비스 개발에 전문성을 가지고 있습니다.

특히 Sensor Game Hub에서는 팀 리더로서 Claude Sonnet 4.5 1M Token을 활용한 AI 게임 생성 플랫폼을 개발했으며, Synapse AI에서는 완전 자동화된 PDF 처리와 벡터 검색 시스템을 구현했습니다. 총 8개의 프로젝트를 통해 실제 환경에서 필요한 솔루션을 구현한 경험이 있으며, 모든 프로젝트가 프로덕션 레벨로 배포되어 운영 중입니다.

또한 Claude Code, Cursor 등 바이브 코딩(Vibe Coding) 툴을 깊이 이해하고 능숙하게 활용하며, 이를 통해 개발 효율을 극대화하고 빠른 프로토타이핑과 실시간 협업이 가능한 개발 환경을 구축해왔습니다.

---

### 3분 버전 (상세)

안녕하세요, 조민혁입니다.

저는 AI와 웹 풀스택 개발에 집중하며, 최신 기술을 활용해 사용자에게 실질적인 가치를 제공하는 서비스를 만들어왔습니다. 특히 **React 19, TypeScript, Supabase**를 중심으로 한 현대적인 웹 애플리케이션 개발과 **OpenAI API, Anthropic API**를 활용한 AI 서비스 개발에 전문성을 가지고 있습니다.

#### 주요 프로젝트 경험

**첫째, AI 서비스 개발 경험**입니다. Sensor Game Hub에서는 팀 리더로서 Claude Sonnet 4.5 1M Token과 Extended Thinking을 활용하여 AI와의 멀티턴 대화를 통해 게임을 생성하는 혁신적인 플랫폼을 개발했습니다. 단순히 AI를 사용하는 것을 넘어, AI를 검증된 프레임워크로 전환하는 구체적인 프롬프트 전략을 설계했습니다.

Synapse AI에서는 완전 자동화된 PDF 처리, AI 요약, pgvector를 활용한 벡터 검색, 실시간 지식 그래프를 제공하는 엔터프라이즈급 지식 관리 시스템을 구현했습니다. 특히 Supabase Edge Functions를 활용한 서버사이드 PDF 텍스트 추출 시스템을 구현하여 CSP 제약 문제를 해결했습니다.

**둘째, 엔터프라이즈급 애플리케이션 개발 경험**입니다. Convi 편의점 종합 솔루션에서는 17개 테이블의 복잡한 데이터베이스를 설계하고, RLS(Row Level Security) 정책을 통해 사용자별 데이터 접근 제어를 100% 달성했습니다. 고객-점주-본사 3자가 실시간으로 연결되는 통합 관리 플랫폼을 구축하여 주문부터 재고 관리, 매출 분석까지 모든 비즈니스 프로세스를 자동화했습니다.

Trading Intelligence에서는 6개의 독립 마이크로서비스(Frontend, Stream, AI, News Crawler, Report, Alert)를 Railway에 배포하여 확장 가능한 아키텍처를 완성했으며, Claude AI와 OpenAI의 오케스트레이션 시스템을 구현하여 AI 분석 비용을 50% 절감했습니다.

**셋째, 실시간 시스템 개발 경험**입니다. Socket.IO, WebSocket, Redis Pub/Sub 등을 활용하여 실시간 데이터 동기화를 구현했으며, 특히 Trading Intelligence에서는 1초 단위 주가 갱신 시스템을 구축했습니다.

**넷째, 협업 및 문서화 경험**입니다. 독독(DockDock) 프로젝트에서는 iOS 개발자와 협업하기 위해 API-First 설계를 채택했으며, 모든 엔드포인트에 Swift 구현 예시를 포함한 완벽한 Swagger 문서화를 제공하여 협업 효율을 극대화했습니다.

#### 개발 철학

저는 단순히 코드를 작성하는 것이 아닌, **사용자 중심의 문제 해결**에 집중합니다. Claude Code, Cursor 등 바이브 코딩(Vibe Coding) 툴을 깊이 이해하고 능숙하게 활용하여 개발 효율을 극대화하고, 창의적 문제 해결 중심의 개발을 실천하고 있습니다.

모든 프로젝트가 프로덕션 레벨로 배포되어 실제 운영 중이며, 각 프로젝트에서 발생한 기술적 도전과 해결 과정을 철저히 문서화하여 지속적으로 학습하고 성장하고 있습니다.

---

### 핵심 역량 요약

| 역량 | 상세 내용 |
|------|-----------|
| **AI 서비스 기획** | OpenAI API, Anthropic API를 활용한 문서 분석, 추천 시스템 등 인공지능 기술을 실제 서비스에 적용한 경험 |
| **풀스택 개발** | React 19, TypeScript, Node.js를 중심으로 한 현대적인 웹 애플리케이션 풀스택 개발 |
| **사용자 중심 설계** | 실제 사용자의 니즈를 파악하고 직관적이며 효율적인 사용자 경험을 설계 |
| **문제 해결** | 복잡한 비즈니스 요구사항을 분석하고 창의적인 기술 솔루션으로 해결 |
| **실시간 시스템** | Socket.IO, WebSocket, Redis Pub/Sub를 활용한 실시간 데이터 동기화 구현 |
| **데이터베이스 설계** | PostgreSQL, Supabase, RLS 정책을 활용한 엔터프라이즈급 데이터베이스 아키텍처 구축 |
| **협업 및 문서화** | API-First 설계, Swagger 문서 자동화, iOS 협업 경험 |
| **바이브 코딩** | Claude Code, Cursor 등 최신 AI 개발 도구를 활용한 효율적 개발 워크플로우 구축 |

---

## 프로젝트별 예상 질문

### 1. Sensor Game Hub - 센서 게임 플랫폼

**프로젝트 개요**: 모바일 센서를 활용한 게임 플랫폼. AI와 대화를 통해 게임 생성 및 유지보수를 자동화. (기간: 2025.08 - 2025.10, 팀 리더)

#### 1.1 AI 기반 게임 생성 시스템

**Q1. Claude Sonnet 4.5 1M Token을 선택한 이유는 무엇인가요?**
- 게임 코드 생성에는 대규모 컨텍스트 윈도우가 필수적입니다
- 1M Token 컨텍스트로 전체 게임 로직, 이전 대화 내역, 시스템 프롬프트를 모두 포함 가능
- Extended Thinking 기능으로 복잡한 게임 로직을 더 깊이 있게 추론 가능
- 기존 GPT-4 대비 코드 품질과 일관성이 훨씬 우수했습니다

**Q2. AI와의 멀티턴 대화를 통한 게임 생성 과정을 설명해주세요.**
1. 사용자가 원하는 게임 컨셉을 자연어로 입력
2. AI가 게임 디자인 문서(GDD)를 생성하고 사용자에게 확인
3. 확정된 GDD 기반으로 게임 코드를 생성 (HTML/CSS/JS)
4. 사용자 테스트 후 피드백을 AI에게 전달
5. AI가 코드를 수정하여 재배포
6. 반복적인 개선을 통해 완성도 높은 게임 완성

**Q3. AI 생성 코드의 품질을 어떻게 보장했나요?**
- 구체적인 프롬프트 전략: "반드시 웹 표준을 준수하라", "모바일 센서 API만 사용하라" 등 명확한 제약 조건 명시
- 코드 검증 시스템: 생성된 코드를 자동으로 파싱하여 문법 오류 검사
- 샌드박스 환경: iframe 내에서 게임을 실행하여 메인 앱에 영향을 주지 않도록 격리
- 에러 핸들링: 런타임 에러 발생 시 AI에게 에러 로그를 전달하여 자동 수정

**Q4. AI API 풀백 시스템은 어떻게 구현했나요?**
- Primary: Anthropic Claude Sonnet 4.5
- Fallback: OpenAI GPT-4 Turbo
- Claude API 실패 시 자동으로 GPT-4 Turbo로 전환
- 사용자에게는 투명하게 처리되며, 서비스 중단 없이 지속적인 서비스 제공
- 에러 로깅을 통해 API 실패 패턴 분석 및 개선

**Q5. 게임 버그 수정 자동화는 어떻게 구현했나요?**
- 사용자가 버그 리포트를 자연어로 작성
- AI가 기존 게임 코드와 버그 설명을 분석
- 수정된 코드를 생성하고 diff를 표시
- 사용자 승인 후 자동 배포
- 버그 수정 이력을 데이터베이스에 저장하여 재발 방지

**Q6. RAG 기반 대화형 매뉴얼 시스템은 어떻게 구현했나요?**
- pgvector를 사용하여 게임 매뉴얼, FAQ 등을 벡터화하여 저장
- 사용자 질문을 임베딩하여 유사도 검색
- 검색된 컨텍스트를 AI에게 전달하여 답변 생성
- 답변 품질 향상을 위해 사용자 피드백 수집 및 벡터 DB 지속 업데이트

#### 1.2 실시간 멀티플레이어 시스템

**Q7. Socket.IO를 선택한 이유는 무엇인가요?**
- WebSocket 기반이지만 폴링 폴백 지원으로 안정성 높음
- 룸(Room) 기능으로 게임 세션 관리 용이
- 이벤트 기반 아키텍처로 코드 가독성 향상
- 네임스페이스 기능으로 게임별 격리 가능

**Q8. 동시 접속자 10명 지원을 어떻게 구현했나요?**
- 게임 세션당 최대 10명 제한 설정
- Redis를 사용하여 세션 상태 관리 (접속자 수, 게임 상태 등)
- 10명 초과 시 대기열에 추가하고 자리가 생기면 자동 입장
- 각 클라이언트의 센서 데이터를 서버에서 집계하여 브로드캐스트

**Q9. WebSocket 연결 안정성은 어떻게 보장했나요?**
- 재연결 로직: 연결 끊김 시 exponential backoff 전략으로 재연결 시도
- Heartbeat 시스템: 10초마다 ping/pong 메시지 교환으로 연결 상태 확인
- 연결 끊김 시 사용자에게 알림 표시 및 게임 상태 저장
- 재연결 시 이전 상태 복원

**Q10. 센서 데이터 지연 문제는 어떻게 해결했나요?**
- 센서 데이터 버퍼링: 클라이언트에서 100ms마다 센서 데이터를 버퍼에 저장
- 예측 알고리즘: 이전 데이터 기반으로 다음 위치를 예측
- 클라이언트 사이드 보간법: 서버 데이터와 예측 데이터를 부드럽게 보간
- 결과: 게임 반응 속도 50% 향상, 사용자 만족도 크게 개선

#### 1.3 팀 리더 경험

**Q11. 팀 리더로서 어떤 역할을 수행했나요?**
- 프로젝트 기획 및 일정 관리
- 기술 스택 선정 및 아키텍처 설계
- 코드 리뷰 및 품질 관리
- 팀원 간 업무 분담 및 협업 조율
- 기술적 문제 해결 지원

**Q12. 팀원과의 협업에서 어려웠던 점은 무엇이었나요?**
- Git 브랜치 전략 통일: Git Flow 도입으로 충돌 최소화
- 코드 컨벤션 통일: ESLint, Prettier 자동화로 일관성 유지
- 커뮤니케이션: 매일 15분 스탠드업 미팅으로 진행 상황 공유
- 기술 이해도 차이: 페어 프로그래밍으로 지식 공유

**Q13. 프로젝트 일정을 어떻게 관리했나요?**
- Notion으로 칸반 보드 관리
- 2주 스프린트 단위로 진행
- 매주 금요일 회고를 통해 개선점 도출
- 중요도와 긴급도를 기준으로 작업 우선순위 설정

#### 1.4 성능 및 보안

**Q14. 메모리 누수 문제는 어떻게 해결했나요?**
- 세션별 리소스 정리 자동화: 게임 종료 시 타이머, 이벤트 리스너 모두 제거
- 가비지 컬렉션 최적화: 대용량 객체는 WeakMap 사용
- 메모리 사용량 모니터링: Chrome DevTools로 메모리 프로파일링
- 결과: 메모리 사용량 40% 감소, 서버 안정성 확보

**Q15. QR 코드 기반 게임 접속 시스템의 보안은 어떻게 보장했나요?**
- QR 코드에 일회용 토큰(UUID) 포함
- 토큰 유효 시간 5분 설정
- 토큰 사용 후 즉시 무효화
- Redis에 토큰 저장하여 중복 사용 방지

---

### 2. Synapse AI - 지능형 지식 관리 시스템

**프로젝트 개요**: 완전 자동화된 PDF 처리, AI 요약, 벡터 검색, 실시간 지식 그래프를 제공하는 혁신적인 지식 관리 플랫폼. (기간: 2025.09 - 현재, 개인 프로젝트)

#### 2.1 PDF 처리 아키텍처

**Q16. PDF를 서버사이드에서 처리한 이유는 무엇인가요?**
- 클라이언트 사이드 PDF 파싱 시 CSP(Content Security Policy) 제약 발생
- PDF.js 등의 라이브러리가 unsafe-eval을 요구하여 보안 위험
- Supabase Edge Functions(Deno 런타임)를 활용하여 서버사이드 처리로 전환
- 결과: 안정적이고 확장 가능한 PDF 처리 아키텍처 완성

**Q17. Supabase Edge Functions를 선택한 이유는 무엇인가요?**
- Supabase와의 네이티브 통합: 데이터베이스, Storage 직접 접근 가능
- Deno 런타임: TypeScript 네이티브 지원, 보안성 높음
- 서버리스: 인프라 관리 부담 없음, 자동 스케일링
- 저렴한 비용: 사용한 만큼만 과금

**Q18. PDF 텍스트 추출은 어떻게 구현했나요?**
```typescript
// Edge Function 예시
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { PDFDocument } from 'npm:pdf-lib'

serve(async (req) => {
  const formData = await req.formData()
  const pdfFile = formData.get('file') as File
  const pdfBytes = await pdfFile.arrayBuffer()
  const pdfDoc = await PDFDocument.load(pdfBytes)

  // 각 페이지에서 텍스트 추출
  const pages = pdfDoc.getPages()
  const texts = await Promise.all(
    pages.map(async (page) => await page.getTextContent())
  )

  return new Response(JSON.stringify({ text: texts.join('\n') }))
})
```

**Q19. 대용량 PDF 처리 시 성능 최적화는 어떻게 했나요?**
- 청킹(Chunking): PDF를 10페이지 단위로 분할하여 병렬 처리
- 스트리밍 업로드: Supabase Storage에 청크 단위로 업로드
- 백그라운드 작업: 사용자에게는 즉시 응답하고, 백그라운드에서 처리
- 진행률 표시: WebSocket으로 실시간 진행률 업데이트

#### 2.2 AI 요약 및 지식 생성

**Q20. OpenAI GPT-4o-mini를 선택한 이유는 무엇인가요?**
- 비용 효율성: GPT-4 대비 10배 저렴
- 충분한 성능: 요약 작업에는 GPT-4o-mini로 충분
- 빠른 응답 속도: 긴 문서 처리에도 2~3초 내 응답
- 임베딩 모델과의 통합: text-embedding-3-small과 함께 사용

**Q21. AI 기반 암기 노트 생성은 어떻게 구현했나요?**
- 사용자가 업로드한 PDF 또는 메모 내용을 분석
- GPT-4o-mini에게 "핵심 개념을 추출하여 Q&A 형식으로 변환하라"는 프롬프트 전달
- 생성된 Q&A를 Supabase에 저장
- 사용자가 복습 시 랜덤하게 질문 출제
- 정답률을 추적하여 약한 부분 집중 학습

**Q22. AI 기반 퀴즈 생성은 어떻게 구현했나요?**
- 4가지 퀴즈 유형 지원: 객관식, 주관식, OX, 빈칸 채우기
- GPT-4o-mini에게 문서 내용과 퀴즈 유형을 전달
- JSON 형식으로 퀴즈 데이터 생성 (질문, 선택지, 정답, 해설)
- 생성된 퀴즈를 데이터베이스에 저장
- 사용자 응답을 분석하여 오답 노트 자동 생성

**Q23. 개인 지식 기반 AI 채팅은 어떻게 구현했나요?**
- RAG(Retrieval-Augmented Generation) 아키텍처 사용
- 사용자 질문을 임베딩하여 벡터 검색 (pgvector)
- 검색된 관련 문서를 컨텍스트로 GPT-4o-mini에게 전달
- AI가 개인 지식 기반으로 답변 생성
- 답변에 사용된 문서 출처 표시

#### 2.3 벡터 검색 시스템

**Q24. pgvector를 선택한 이유는 무엇인가요?**
- Supabase와 네이티브 통합: PostgreSQL 확장으로 제공
- SQL 쿼리로 벡터 검색 가능: 별도의 벡터 DB 불필요
- 하이브리드 검색 지원: 텍스트 검색(Full-Text Search)과 벡터 검색 결합 가능
- 성능: 인덱싱 알고리즘(IVFFlat, HNSW)으로 빠른 검색

**Q25. 벡터 임베딩 생성 과정을 설명해주세요.**
1. PDF 텍스트 추출 후 512 토큰 단위로 청킹
2. OpenAI text-embedding-3-small 모델로 임베딩 생성 (1536 차원)
3. 각 청크와 임베딩을 Supabase에 저장
4. pgvector로 벡터 인덱스 생성 (HNSW 알고리즘)
5. 사용자 쿼리 임베딩과 코사인 유사도 계산하여 검색

**Q26. 벡터 검색 성능은 어떻게 최적화했나요?**
```sql
-- HNSW 인덱스 생성 (Hierarchical Navigable Small World)
CREATE INDEX ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- 하이브리드 검색 쿼리
SELECT * FROM documents
WHERE to_tsvector('english', content) @@ to_tsquery('search term')
ORDER BY embedding <=> query_embedding
LIMIT 10;
```
- HNSW 인덱스로 검색 속도 10배 향상
- 하이브리드 검색으로 정확도 향상: 키워드 매칭 + 의미 검색
- 캐싱: 자주 검색되는 쿼리 결과를 Redis에 저장

**Q27. 의미 검색의 정확도를 어떻게 검증했나요?**
- 테스트 데이터셋 구축: 100개 문서 + 50개 질문
- 평가 지표: Top-K Accuracy, MRR(Mean Reciprocal Rank)
- 임베딩 모델 비교: text-embedding-3-small vs text-embedding-ada-002
- 결과: text-embedding-3-small이 정확도 12% 향상, 비용 50% 절감

#### 2.4 실시간 지식 그래프

**Q28. 지식 그래프는 어떻게 구현했나요?**
- D3.js를 사용하여 인터랙티브 그래프 시각화
- 노드: 문서, 개념, 태그
- 엣지: 문서 간 유사도 (벡터 거리 기반)
- 레이아웃: Force-Directed Graph 알고리즘
- 사용자가 노드 클릭 시 해당 문서로 이동

**Q29. 문서 간 유사도는 어떻게 계산했나요?**
- 모든 문서의 임베딩 벡터를 가져옴
- 각 문서 쌍의 코사인 유사도 계산
- 유사도가 0.7 이상인 경우에만 엣지 생성
- 유사도를 엣지 두께로 시각화

**Q30. D3.js를 선택한 이유는 무엇인가요?**
- 고도의 커스터마이징 가능
- 대용량 데이터 처리 성능 우수
- 인터랙티브 애니메이션 지원
- React와 통합 용이 (useRef로 DOM 직접 조작)

---

### 3. Convi - 편의점 종합 솔루션

**프로젝트 개요**: 완전한 상용 수준의 편의점 통합 관리 플랫폼. 고객, 점주, 본사가 실시간으로 연결되어 주문부터 재고 관리, 매출 분석까지 모든 비즈니스 프로세스를 자동화. (기간: 2025.08 - 2025.09, 팀 프로젝트)

#### 3.1 데이터베이스 설계

**Q31. 17개 테이블 데이터베이스는 어떻게 설계했나요?**

**주요 테이블 구조:**
1. **사용자 관리**: profiles, stores
2. **상품 관리**: categories, products, store_products
3. **주문 관리**: orders, order_items, order_status_history
4. **물류 관리**: supply_requests, supply_request_items, shipments
5. **재고 관리**: inventory_transactions
6. **분석 관리**: daily_sales_summary, product_sales_summary
7. **시스템 관리**: notifications, system_settings

**설계 원칙:**
- 정규화: 제3정규형(3NF)까지 정규화하여 데이터 중복 최소화
- 인덱싱: 자주 검색되는 컬럼(user_id, store_id, product_id)에 인덱스 생성
- 외래 키: 참조 무결성 보장 (ON DELETE CASCADE)
- 타임스탬프: 모든 테이블에 created_at, updated_at 컬럼 추가

**Q32. RLS(Row Level Security) 정책은 어떻게 구현했나요?**
```sql
-- 고객은 자신의 주문만 조회 가능
CREATE POLICY "customers_own_orders" ON orders
  FOR SELECT
  USING (auth.uid() = user_id AND role = 'customer');

-- 점주는 자신의 점포 주문만 조회 가능
CREATE POLICY "owners_store_orders" ON orders
  FOR SELECT
  USING (
    store_id IN (
      SELECT id FROM stores WHERE owner_id = auth.uid()
    )
  );

-- 본사는 모든 주문 조회 가능
CREATE POLICY "headquarters_all_orders" ON orders
  FOR SELECT
  USING (
    EXISTS (
      SELECT 1 FROM profiles
      WHERE id = auth.uid() AND role = 'headquarters'
    )
  );
```

**Q33. 데이터베이스 성능 최적화는 어떻게 했나요?**
- 복합 인덱스 생성: (store_id, created_at), (user_id, status) 등
- 뷰(View) 생성: 자주 사용되는 복잡한 조인 쿼리를 뷰로 미리 정의
- 파티셔닝: orders 테이블을 월별로 파티셔닝하여 검색 속도 향상
- Materialized View: 매출 집계 데이터를 Materialized View로 캐싱

#### 3.2 실시간 데이터 동기화

**Q34. Supabase Realtime은 어떻게 활용했나요?**
```typescript
// 실시간 주문 구독 (점주용)
const subscription = supabase
  .channel('store-orders')
  .on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'orders',
      filter: `store_id=eq.${storeId}`
    },
    (payload) => {
      // 새 주문 알림 표시
      toast.success('새로운 주문이 들어왔습니다!')
      // 주문 목록 업데이트
      setOrders(prev => [payload.new, ...prev])
    }
  )
  .subscribe()
```

**Q35. 실시간 동기화 성능 이슈는 어떻게 해결했나요?**
- 선택적 구독: 필요한 데이터만 구독 (store_id 필터링)
- Debouncing: 빠르게 발생하는 업데이트를 100ms 단위로 병합
- Optimistic UI: 서버 응답 전에 UI 먼저 업데이트
- 연결 풀 관리: 사용하지 않는 구독은 자동 해제

**Q36. 3자(고객-점주-본사) 실시간 통합은 어떻게 구현했나요?**
- 고객: 주문 상태 변경 시 실시간 알림 (예: "조리 중" → "준비 완료")
- 점주: 신규 주문, 재고 부족 알림
- 본사: 점포 승인 요청, 물류 승인 요청 알림
- 각 역할별로 별도의 Realtime 채널 구독
- 알림은 notifications 테이블에 저장하여 히스토리 관리

#### 3.3 토스페이먼츠 결제 연동

**Q37. 토스페이먼츠를 선택한 이유는 무엇인가요?**
- 간편한 연동: SDK 제공으로 빠른 구현 가능
- 다양한 결제 수단: 카드, 계좌이체, 간편결제 모두 지원
- 실시간 결제 검증: 웹훅으로 결제 상태 실시간 확인
- 자동 환불: API로 환불 처리 자동화 가능

**Q38. 결제 프로세스를 설명해주세요.**
1. 클라이언트: 토스페이먼츠 SDK로 결제 요청
2. 토스페이먼츠: 결제 위젯 표시, 사용자 결제 진행
3. 클라이언트: 결제 성공 시 orderId, paymentKey를 서버에 전송
4. 서버: 토스페이먼츠 API로 결제 승인 요청
5. 토스페이먼츠: 결제 승인 응답 (성공/실패)
6. 서버: 결제 정보를 데이터베이스에 저장
7. 클라이언트: 주문 완료 페이지로 리다이렉트

**Q39. 결제 상태 관리는 어떻게 했나요?**
```typescript
type PaymentStatus =
  | 'PENDING'    // 결제 대기
  | 'IN_PROGRESS' // 결제 진행 중
  | 'COMPLETED'   // 결제 완료
  | 'FAILED'      // 결제 실패
  | 'CANCELED'    // 결제 취소
  | 'REFUNDED'    // 환불 완료

// 커스텀 훅으로 결제 상태 추적
const usePayment = () => {
  const [status, setStatus] = useState<PaymentStatus>('PENDING')
  const [error, setError] = useState<string | null>(null)

  const requestPayment = async (amount: number) => {
    setStatus('IN_PROGRESS')
    try {
      const result = await tossPayments.requestPayment(...)
      setStatus('COMPLETED')
      return result
    } catch (err) {
      setStatus('FAILED')
      setError(err.message)
    }
  }

  return { status, error, requestPayment }
}
```

**Q40. 결제 실패 시 복구 전략은 무엇인가요?**
- 재시도 메커니즘: 네트워크 오류 시 자동으로 3회까지 재시도
- 사용자 알림: 명확한 에러 메시지 표시 ("카드 한도 초과", "잔액 부족" 등)
- 주문 상태 롤백: 결제 실패 시 주문 상태를 'PENDING'으로 복원
- 로깅: 모든 결제 시도를 로그에 기록하여 디버깅 용이

#### 3.4 재고 관리 시스템

**Q41. 실시간 재고 관리는 어떻게 구현했나요?**
- 주문 발생 시 재고 자동 차감
- 재고가 설정된 임계값 이하로 떨어지면 점주에게 알림
- 재고 히스토리 추적 (inventory_transactions 테이블)
- 본사에 자동 발주 요청 기능

**Q42. 동시성 제어는 어떻게 처리했나요?**
```sql
-- Optimistic Locking (낙관적 잠금)
UPDATE store_products
SET quantity = quantity - 1,
    version = version + 1
WHERE id = $1 AND version = $2;

-- 영향받은 행이 0이면 재시도
-- Pessimistic Locking (비관적 잠금)
BEGIN;
SELECT * FROM store_products
WHERE id = $1
FOR UPDATE;  -- 행 잠금

UPDATE store_products
SET quantity = quantity - 1
WHERE id = $1;
COMMIT;
```

**Q43. 재고 부족 시 어떻게 처리했나요?**
- 실시간 재고 확인: 주문 전에 재고 여부 확인
- 재고 부족 시 사용자에게 알림 표시
- 대체 상품 추천: 유사 상품을 AI로 추천
- 입고 예정일 안내: 다음 입고 일정 표시

---

### 4. 한 숨의 위로 - 감정 AI 상담 서비스

**프로젝트 개요**: OpenAI GPT API를 활용한 감정 분석 및 AI 상담 서비스. 사용자의 일기를 분석하여 감정 상태를 파악하고, 맞춤형 피드백과 음악 추천 제공. (기간: 2025.03 - 2025.04, 개인 프로젝트)

#### 4.1 GPT-4 감정 분석

**Q44. 감정 분석 프롬프트는 어떻게 설계했나요?**
```javascript
const systemPrompt = `
당신은 전문 심리 상담사입니다. 사용자의 일기를 읽고 감정 상태를 분석해주세요.

## 분석 항목
1. 주요 감정 (기쁨, 슬픔, 분노, 불안, 평온 등)
2. 감정 강도 (1-10점)
3. 감정 원인 (가족, 친구, 업무, 건강 등)
4. 우울증 위험도 (낮음, 중간, 높음)

## 출력 형식 (JSON)
{
  "emotion": "슬픔",
  "intensity": 7,
  "cause": ["가족", "업무"],
  "depression_risk": "중간",
  "keywords": ["외로움", "피곤함", "불안"]
}

## 주의사항
- 자살, 자해 등 극단적 표현이 있으면 depression_risk를 "높음"으로 설정
- 한국어 맥락을 고려한 감정 분석
- 객관적이고 공감적인 톤 유지
`
```

**Q45. 프롬프트 엔지니어링을 통해 정확도를 어떻게 향상시켰나요?**
1. **Few-Shot Learning**: 10개의 예시 일기와 정답 감정 분석 제공
2. **Chain-of-Thought**: AI에게 단계별로 분석하도록 유도
3. **한국어 특화**: "화남"과 "짜증", "슬픔"과 "우울" 등 미묘한 차이 명시
4. **컨텍스트 제공**: 과거 일기 데이터를 함께 전달하여 감정 변화 추이 파악
5. **결과 검증**: AI 응답을 파싱하여 형식 검증, 오류 시 재요청

**Q46. 감정 분석 정확도는 어떻게 측정했나요?**
- 테스트 데이터셋: 100개 일기 + 전문가 라벨링
- 평가 지표: Accuracy, Precision, Recall, F1 Score
- 초기 정확도: 78%
- 프롬프트 개선 후: 92%
- 오분류 사례 분석: 아이러니, 은유 표현 등에서 오류 발생

#### 4.2 위기 상황 대응

**Q47. 자살·극단적 표현 자동 감지는 어떻게 구현했나요?**
```javascript
// 위험 키워드 목록
const dangerKeywords = [
  '자살', '죽고 싶다', '사라지고 싶다',
  '자해', '칼', '약', '뛰어내리다'
]

// 감정 분석 후 위험도 판단
const analyzeDiary = async (content) => {
  const emotion = await analyzeEmotion(content)

  // 위험 키워드 검사
  const hasDanger = dangerKeywords.some(keyword =>
    content.includes(keyword)
  )

  // 우울증 위험도 또는 위험 키워드 발견 시
  if (emotion.depression_risk === '높음' || hasDanger) {
    await sendAlert(userId)
    await showCrisisMessage(userId)
  }
}

// 위기 메시지 표시
const showCrisisMessage = async (userId) => {
  await createNotification({
    userId,
    title: '당신은 소중한 사람입니다',
    message: `
      힘든 시간을 보내고 계신가요?
      전문가의 도움을 받으실 수 있습니다.

      📞 자살예방 상담전화: 1393
      💬 카카오톡 상담: "마음이음"
    `,
    type: 'CRISIS',
    priority: 'HIGH'
  })
}
```

**Q48. 위기 대응 시스템의 효과는 어떻게 검증했나요?**
- 테스트 사용자 10명에게 위험 일기 작성 요청
- 10명 모두 즉시 위기 메시지 수신 확인
- 사용자 피드백: "따뜻한 메시지에 위로받았다"
- 실제 전문 상담 연결: 3명이 1393 전화상담 이용

#### 4.3 Spotify API 음악 추천

**Q49. 감정 기반 음악 매칭 로직을 설명해주세요.**
```javascript
// 감정별 Spotify 장르 매핑
const emotionToGenre = {
  '기쁨': ['pop', 'dance', 'k-pop'],
  '슬픔': ['sad', 'acoustic', 'piano'],
  '분노': ['rock', 'metal', 'punk'],
  '불안': ['ambient', 'meditation', 'classical'],
  '평온': ['jazz', 'chill', 'lo-fi']
}

// Spotify API로 추천 음악 검색
const recommendMusic = async (emotion, intensity) => {
  const genres = emotionToGenre[emotion]

  // 감정 강도에 따라 Spotify Audio Features 조정
  const features = {
    energy: intensity / 10,  // 0.0 ~ 1.0
    valence: emotion === '기쁨' ? 0.8 : 0.2,
    danceability: emotion === '기쁨' ? 0.7 : 0.3
  }

  const tracks = await spotify.getRecommendations({
    seed_genres: genres,
    target_energy: features.energy,
    target_valence: features.valence,
    limit: 10
  })

  return tracks
}
```

**Q50. Spotify API 토큰 만료 문제는 어떻게 해결했나요?**
- Access Token 유효 기간: 1시간
- Refresh Token으로 자동 갱신
- Redis에 토큰 캐싱 (TTL 55분 설정)
- 백그라운드 크론 잡: 50분마다 토큰 갱신
- 토큰 만료 시 자동 재로그인 유도

#### 4.4 커뮤니티 기능

**Q51. 일기 공유 및 피드백 시스템은 어떻게 구현했나요?**
- 사용자가 일기 작성 후 "공개" 옵션 선택 가능
- 공개 일기는 커뮤니티 피드에 표시 (최신순, 인기순)
- 다른 사용자가 공감(하트), 댓글 작성 가능
- 부적절한 댓글 신고 기능
- 작성자는 언제든지 비공개로 전환 가능

**Q52. 주간/월간 감정 패턴 분석은 어떻게 구현했나요?**
- 매일 밤 12시 크론 잡 실행: 당일 일기 감정 분석 결과를 집계
- 주간 리포트: 7일간 주요 감정 비율, 감정 변화 그래프
- 월간 리포트: 30일간 감정 트렌드, 가장 행복했던 날/슬펐던 날
- Chart.js로 시각화: Line Chart(감정 변화), Pie Chart(감정 비율)
- 인사이트 제공: "이번 주는 평소보다 긍정적인 감정이 20% 증가했어요!"

---

### 5. 독독 (DockDock) - 독서 관리 플랫폼

**프로젝트 개요**: 독서 기록, 진행 상황 추적, AI 기반 맞춤 책 추천까지 제공하는 종합 독서 관리 플랫폼. React와 Supabase, OpenAI API를 활용한 웹 플랫폼 서비스. (기간: 2025.10 - 현재, 개인 프로젝트 / iOS 협업)

#### 5.1 API-First 설계

**Q53. API-First 설계를 선택한 이유는 무엇인가요?**
- iOS 개발자와 협업을 위해 백엔드 API를 먼저 설계
- 웹과 iOS가 동일한 API를 사용하여 일관성 보장
- API 먼저 완성하면 프론트엔드 개발이 독립적으로 진행 가능
- Swagger 문서를 기반으로 명확한 스펙 공유

**Q54. Swagger 문서 자동화는 어떻게 구현했나요?**
```javascript
// Express + Swagger JSDoc
/**
 * @swagger
 * /api/books/search:
 *   get:
 *     summary: 알라딘 API로 도서 검색
 *     tags: [Books]
 *     parameters:
 *       - in: query
 *         name: keyword
 *         required: true
 *         schema:
 *           type: string
 *         description: 검색 키워드
 *     responses:
 *       200:
 *         description: 검색 성공
 *         content:
 *           application/json:
 *             schema:
 *               type: array
 *               items:
 *                 $ref: '#/components/schemas/Book'
 *     x-code-samples:
 *       - lang: Swift
 *         source: |
 *           let url = "\(baseURL)/api/books/search?keyword=\(keyword)"
 *           let (data, _) = try await URLSession.shared.data(from: URL(string: url)!)
 *           let books = try JSONDecoder().decode([Book].self, from: data)
 */
app.get('/api/books/search', async (req, res) => { ... })
```

**Q55. iOS 개발자와의 협업은 어떻게 진행했나요?**
- 매주 월요일 API 스펙 회의: 변경 사항 공유
- Swagger 문서를 단일 진실 공급원(Single Source of Truth)으로 사용
- API 변경 시 버전 관리: /v1/api, /v2/api
- iOS 개발자가 직접 Swagger UI에서 API 테스트 가능
- Postman Collection 공유로 빠른 테스트 가능

#### 5.2 AI 추천 시스템

**Q56. OpenAI GPT-4o를 사용한 추천 시스템은 어떻게 구현했나요?**
```javascript
// 사용자 독서 히스토리 기반 추천
const recommendBooks = async (userId) => {
  // 사용자가 읽은 책 목록 가져오기
  const readBooks = await getUserReadBooks(userId)

  // GPT-4o에게 추천 요청
  const prompt = `
    사용자가 읽은 책:
    ${readBooks.map(b => `- ${b.title} (${b.author})`).join('\n')}

    이 사용자에게 추천할 만한 책 5권을 JSON 형식으로 추천해주세요.
    각 책은 title, author, reason(추천 이유)를 포함해야 합니다.
  `

  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' }
  })

  const recommendations = JSON.parse(response.choices[0].message.content)

  // 알라딘 API로 실제 책 정보 가져오기
  const books = await Promise.all(
    recommendations.books.map(async (rec) => {
      const book = await searchAladinBook(rec.title)
      return { ...book, reason: rec.reason }
    })
  )

  return books
}
```

**Q57. AI 추천의 정확도를 어떻게 향상시켰나요?**
- 사용자 프로필 정보 활용: 선호 장르, 선호 작가, 독서 목적
- 평점 데이터 반영: 사용자가 높은 평점을 준 책과 유사한 책 추천
- Few-Shot Learning: 10개의 추천 예시를 프롬프트에 포함
- 다양성 보장: 같은 작가의 책만 추천하지 않도록 제약 조건 추가

**Q58. Redis 24시간 캐싱은 왜 적용했나요?**
- AI 추천은 계산 비용이 높음 (GPT-4o 호출 + 알라딘 API 호출)
- 사용자의 독서 히스토리는 자주 변하지 않음
- 24시간 동안은 동일한 추천 결과 제공
- 새 책을 읽거나 평점을 남기면 캐시 무효화
- 결과: API 응답 속도 10배 향상, OpenAI 비용 90% 절감

#### 5.3 알라딘 API 연동

**Q59. 알라딘 API를 선택한 이유는 무엇인가요?**
- 국내 최대 도서 데이터베이스
- 무료 API 제공 (일 5,000건)
- 상세한 책 정보: 표지, 저자, 출판사, ISBN, 카테고리 등
- 베스트셀러, 신간 정보 제공

**Q60. 알라딘 API와 내부 books 테이블 간 ID 불일치 문제는 어떻게 해결했나요?**
- **문제**: AI 추천은 내부 book_id 반환, 책 상세는 aladin_id 필요
- **해결책**:
  1. books 테이블에 `aladin_id` 컬럼 추가
  2. 책 저장 시 알라딘 ISBN을 `aladin_id`로 저장
  3. AI 추천 응답에 `{ id, aladinId }` 모두 포함
  4. 프론트엔드에서 책 상세 조회 시 `aladinId` 사용
- **결과**: API 일관성 확보, 프론트엔드 에러 완전 해결

#### 5.4 소셜 로그인 iOS 연동

**Q61. Supabase Auth를 활용한 소셜 로그인은 어떻게 구현했나요?**
- Apple 로그인: iOS에서 Sign in with Apple로 ID Token 발급
- 카카오 로그인: 카카오 SDK로 ID Token 발급
- 백엔드 API 엔드포인트: `/api/auth/social-login`
- ID Token을 검증하고 Supabase Auth에 사용자 생성
- JWT 토큰 발급하여 iOS 앱에 반환

**Q62. ID Token 검증은 어떻게 했나요?**
```javascript
// Apple ID Token 검증
const verifyAppleToken = async (idToken) => {
  const decoded = jwt.decode(idToken, { complete: true })

  // Apple 공개 키 가져오기
  const applePublicKey = await fetchApplePublicKey(decoded.header.kid)

  // 서명 검증
  const verified = jwt.verify(idToken, applePublicKey, {
    algorithms: ['RS256'],
    issuer: 'https://appleid.apple.com',
    audience: process.env.APPLE_CLIENT_ID
  })

  return verified.sub // Apple User ID
}

// Supabase Auth에 사용자 생성
const { user } = await supabase.auth.admin.createUser({
  email: appleUserId + '@appleid.com',
  email_confirm: true,
  user_metadata: {
    provider: 'apple',
    provider_id: appleUserId
  }
})
```

---

### 6. Trading Intelligence - AI 트레이딩 플랫폼

**프로젝트 개요**: 시니어 투자자를 위해 설계된 AI 기반 실시간 주식 분석 플랫폼. WebSocket 기반 1초 단위 주가 갱신, Claude AI와 OpenAI 오케스트레이션을 통한 종합 분석, TTS 음성 알림. (기간: 2025.10 - 현재, 개인 프로젝트)

#### 6.1 마이크로서비스 아키텍처

**Q63. 6개 마이크로서비스로 분리한 이유는 무엇인가요?**

**서비스 구조:**
1. **Frontend** (React 19 + TypeScript): 사용자 UI
2. **Stream** (Python + FastAPI): 실시간 주가 스트리밍
3. **AI** (Python + FastAPI): AI 분석 오케스트레이션
4. **News Crawler** (Python): 뉴스 크롤링 및 감성 분석
5. **Report** (Python + FastAPI): 종합 레포트 생성
6. **Alert** (Python + FastAPI): 알림 발송 (TTS + 토스트)

**분리 이유:**
- **독립적 확장**: 트래픽이 많은 Stream 서비스만 스케일 아웃 가능
- **장애 격리**: 한 서비스 장애가 전체 시스템에 영향 주지 않음
- **기술 스택 유연성**: 각 서비스가 최적의 기술 선택 가능
- **배포 독립성**: 서비스별 독립 배포로 빠른 릴리스

**Q64. Railway에서 서비스 간 통신은 어떻게 구현했나요?**
```python
# Railway 서비스 간 참조 (환경 변수)
STREAM_URL = os.getenv('STREAM_URL')  # ${{stream.RAILWAY_PUBLIC_DOMAIN}}
AI_URL = os.getenv('AI_URL')          # ${{ai.RAILWAY_PUBLIC_DOMAIN}}

# Frontend → Stream 서비스 WebSocket 연결
const socket = new WebSocket(`wss://${STREAM_URL}/ws`)

# AI 서비스 → News Crawler 서비스 HTTP 호출
async def get_news(stock_code):
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{NEWS_CRAWLER_URL}/news/{stock_code}")
        return response.json()
```

**Q65. 마이크로서비스 배포 파이프라인은 어떻게 구축했나요?**
- GitHub 연동: main 브랜치 푸시 시 자동 배포
- Railway.json 설정: 각 서비스의 빌드 명령, 시작 명령 정의
- 환경 변수 관리: Railway Dashboard에서 중앙 관리
- 헬스 체크: 각 서비스에 `/health` 엔드포인트 추가
- 롤백: 배포 실패 시 이전 버전으로 자동 롤백

#### 6.2 AI 오케스트레이션

**Q66. Claude AI와 OpenAI를 함께 사용한 이유는 무엇인가요?**
- Claude AI (메인):
  - 장점: 더 깊이 있는 분석, 한국어 이해도 높음
  - 단점: 가끔 API 불안정
- OpenAI (폴백):
  - 장점: 안정적인 API, 빠른 응답
  - 단점: 분석 깊이가 Claude보다 부족
- 오케스트레이션: Claude 우선 시도, 실패 시 OpenAI로 자동 전환
- 결과: AI 서비스 가용성 99.9% 달성, 비용 50% 절감

**Q67. AI 오케스트레이션 로직을 설명해주세요.**
```python
async def analyze_stock(stock_code: str, news: list, technical_data: dict):
    try:
        # 1차 시도: Claude AI (Sonnet 3.5)
        result = await claude_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=2000,
            messages=[{
                "role": "user",
                "content": f"다음 주식을 분석해주세요:\n종목: {stock_code}\n뉴스: {news}\n기술적 지표: {technical_data}"
            }]
        )
        return result.content[0].text

    except Exception as e:
        logger.warning(f"Claude API 실패: {e}. OpenAI로 폴백.")

        # 2차 시도: OpenAI (GPT-4)
        result = await openai_client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[{
                "role": "user",
                "content": f"다음 주식을 분석해주세요:\n종목: {stock_code}\n뉴스: {news}\n기술적 지표: {technical_data}"
            }]
        )
        return result.choices[0].message.content
```

**Q68. AI 분석 비용을 50% 절감한 방법은 무엇인가요?**
1. **Redis 24시간 캐싱**: 동일한 종목 분석 요청은 캐시에서 반환
2. **효율적 프롬프트**: 불필요한 설명 제거, 핵심만 요청
3. **청크 단위 뉴스 요약**: 뉴스 100개를 한 번에 분석하지 않고, 10개씩 요약 후 최종 종합
4. **Claude 3.5 Sonnet 사용**: GPT-4 Turbo 대비 30% 저렴
5. **배치 처리**: 여러 사용자의 요청을 모아서 한 번에 처리

#### 6.3 실시간 시스템

**Q69. WebSocket + Redis Pub/Sub 조합의 장점은 무엇인가요?**
- **WebSocket**: 클라이언트 ↔ 서버 양방향 실시간 통신
- **Redis Pub/Sub**: 서버 ↔ 서버 간 메시지 브로커
- **조합의 이점**:
  - Stream 서비스가 KIS API에서 주가 받아서 Redis에 Publish
  - 여러 Frontend 서버가 Redis를 Subscribe하여 모든 클라이언트에게 전달
  - 서버 확장 시에도 모든 클라이언트가 동일한 데이터 수신

**Q70. 1초 단위 주가 갱신은 어떻게 구현했나요?**
```python
# Stream 서비스 (FastAPI + WebSocket)
import asyncio
from fastapi import WebSocket

# KIS API 토큰 캐싱
kis_token = None

async def get_kis_token():
    global kis_token
    if kis_token is None or is_token_expired(kis_token):
        kis_token = await fetch_new_token()
    return kis_token

async def stream_stock_prices(websocket: WebSocket, stock_code: str):
    await websocket.accept()

    while True:
        try:
            # KIS API에서 현재가 조회
            token = await get_kis_token()
            price_data = await fetch_stock_price(stock_code, token)

            # Redis에 Publish
            await redis.publish(f"stock:{stock_code}", json.dumps(price_data))

            # WebSocket으로 클라이언트에게 전송
            await websocket.send_json(price_data)

            # 1초 대기
            await asyncio.sleep(1)

        except Exception as e:
            logger.error(f"스트리밍 오류: {e}")
            await websocket.close()
            break
```

**Q71. KIS API Rate Limit 문제는 어떻게 해결했나요?**
- **문제**: KIS API는 초당 20건, 일 10,000건 제한
- **해결책**:
  1. **토큰 캐싱**: .kis-token-cache.json 파일에 토큰 저장 (2시간 유효)
  2. **Rate Limiter**: 초당 최대 15건으로 제한 (여유 확보)
  3. **요청 큐**: 여러 사용자 요청을 큐에 넣고 순차 처리
  4. **배치 처리**: 여러 종목을 한 번의 API 호출로 조회
- **결과**: API 호출 횟수 70% 감소

#### 6.4 시니어 접근성

**Q72. 시니어 사용자를 위한 UI/UX는 어떻게 설계했나요?**
- **큰 폰트**: 기본 18px, 제목 24px 이상
- **고대비 모드**: 흰색 배경 + 검은색 텍스트 (명도 대비 7:1)
- **간결한 UI**: 핵심 정보만 표시, 복잡한 차트 최소화
- **TTS 음성 읽기**: 모든 텍스트를 음성으로 읽어주기
- **큰 버튼**: 터치 영역 최소 48x48px
- **직관적 아이콘**: 문자보다 아이콘 우선 (📈 상승, 📉 하락)

**Q73. TTS 음성 알림은 어떻게 구현했나요?**
```typescript
// Web Speech API 사용
const speakText = (text: string) => {
  const utterance = new SpeechSynthesisUtterance(text)
  utterance.lang = 'ko-KR'
  utterance.rate = 0.9  // 약간 느리게
  utterance.pitch = 1.0
  utterance.volume = 1.0

  speechSynthesis.speak(utterance)
}

// 알림 발생 시 자동 음성 읽기
const showAlert = (message: string) => {
  toast.info(message)  // 토스트 알림
  speakText(message)   // 음성 읽기
}

// 예시: "삼성전자 주가가 70,000원을 돌파했습니다!"
```

---

### 7. ReviseAI - AI 코드 리뷰 도구

**프로젝트 개요**: OpenAI API를 활용한 자동 코드 리뷰 및 최적화 제안 도구. (기간: 2025.09 - 진행중, 개인 프로젝트)

#### 7.1 코드 분석 시스템

**Q74. Tree-sitter 파서를 선택한 이유는 무엇인가요?**
- 다중 언어 지원: 40개 이상의 프로그래밍 언어
- AST(Abstract Syntax Tree) 생성: 코드 구조 정확히 파악
- 증분 파싱: 코드 일부만 변경 시 전체 재파싱 불필요
- 에러 복구: 문법 오류가 있어도 파싱 가능
- 빠른 속도: Rust로 작성되어 성능 우수

**Q75. 청크 단위 코드 분석은 어떻게 구현했나요?**
```python
# 10MB 이상 파일을 1,000줄 단위로 분할
def chunk_code(code: str, chunk_size: int = 1000):
    lines = code.split('\n')
    chunks = []

    for i in range(0, len(lines), chunk_size):
        chunk = '\n'.join(lines[i:i+chunk_size])
        chunks.append({
            'content': chunk,
            'start_line': i + 1,
            'end_line': min(i + chunk_size, len(lines))
        })

    return chunks

# 각 청크를 병렬로 분석
async def analyze_large_file(file_path: str):
    code = read_file(file_path)
    chunks = chunk_code(code)

    # 병렬 처리
    tasks = [analyze_chunk(chunk) for chunk in chunks]
    results = await asyncio.gather(*tasks)

    # 결과 병합
    return merge_results(results)
```

**Q76. 다중 언어 지원 아키텍처를 설명해주세요.**
```python
# 공통 분석 인터페이스
class CodeAnalyzer(ABC):
    @abstractmethod
    def parse(self, code: str) -> AST:
        pass

    @abstractmethod
    def analyze(self, ast: AST) -> AnalysisResult:
        pass

# 언어별 구현
class PythonAnalyzer(CodeAnalyzer):
    def __init__(self):
        self.parser = Parser()
        self.parser.set_language(Language('tree-sitter-python'))

    def parse(self, code: str) -> AST:
        return self.parser.parse(bytes(code, 'utf8'))

    def analyze(self, ast: AST) -> AnalysisResult:
        # Python 특화 분석 로직
        return AnalysisResult(...)

# 새 언어 추가 시 CodeAnalyzer 상속
class JavaScriptAnalyzer(CodeAnalyzer):
    ...
```

#### 7.2 AI 기반 리뷰

**Q77. 코드 품질 점수는 어떻게 산출했나요?**
```python
# OpenAI API로 코드 분석
async def calculate_quality_score(code: str, language: str):
    prompt = f"""
    다음 {language} 코드의 품질을 분석하고 100점 만점으로 점수를 매겨주세요.

    ## 평가 항목
    1. 가독성 (Readability): 변수명, 함수명, 주석
    2. 유지보수성 (Maintainability): 코드 복잡도, 모듈화
    3. 성능 (Performance): 알고리즘 효율성, 불필요한 연산
    4. 보안 (Security): 취약점, 입력 검증
    5. 베스트 프랙티스 (Best Practices): 언어별 권장 사항

    ## 출력 형식 (JSON)
    {{
      "total_score": 85,
      "scores": {{
        "readability": 90,
        "maintainability": 80,
        "performance": 85,
        "security": 80,
        "best_practices": 90
      }},
      "suggestions": ["변수명을 더 명확하게", "에러 핸들링 추가"]
    }}

    코드:
    ```{language}
    {code}
    ```
    """

    response = await openai.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)
```

**Q78. 성능 최적화 제안은 어떻게 생성했나요?**
- AST 분석으로 비효율적 패턴 탐지 (예: 중첩 반복문, O(n²) 알고리즘)
- GPT-4에게 개선 방법 요청
- Before/After 코드 비교 제공
- Big-O 복잡도 분석

---

### 8. AI Doc Generator - 문서 자동 생성

**프로젝트 개요**: Next.js와 AI를 결합한 개발 문서 자동 생성 도구. 코드 주석과 구조를 분석하여 API 문서, README, 기술 명세서를 자동으로 생성. (기간: 2025.04 - 2025.07, 개인 프로젝트)

#### 8.1 Next.js 14 아키텍처

**Q79. Next.js 14를 선택한 이유는 무엇인가요?**
- **App Router**: 파일 기반 라우팅으로 직관적 구조
- **Server Components**: 서버 사이드 렌더링으로 초기 로딩 속도 향상
- **API Routes**: 풀스택 애플리케이션 구축 용이
- **Vercel 배포**: 원클릭 배포 및 자동 스케일링

**Q80. 코드 구조 분석은 어떻게 구현했나요?**
```typescript
// AST 파싱으로 함수, 클래스 추출
import * as ts from 'typescript'

function analyzeCodeStructure(code: string) {
  const sourceFile = ts.createSourceFile(
    'temp.ts',
    code,
    ts.ScriptTarget.Latest
  )

  const functions: Function[] = []
  const classes: Class[] = []

  function visit(node: ts.Node) {
    if (ts.isFunctionDeclaration(node)) {
      functions.push({
        name: node.name?.text || 'anonymous',
        parameters: node.parameters.map(p => p.name.getText()),
        returnType: node.type?.getText() || 'any',
        comment: extractJSDoc(node)
      })
    }

    if (ts.isClassDeclaration(node)) {
      classes.push({
        name: node.name?.text || 'anonymous',
        methods: extractMethods(node),
        properties: extractProperties(node)
      })
    }

    ts.forEachChild(node, visit)
  }

  visit(sourceFile)

  return { functions, classes }
}
```

**Q81. 10가지 문서 템플릿은 무엇인가요?**
1. **README.md**: 프로젝트 개요, 설치 방법, 사용법
2. **API 문서**: REST API 엔드포인트 자동 생성
3. **기술 명세서**: 시스템 아키텍처, 기술 스택
4. **사용자 가이드**: 기능별 사용 방법
5. **개발자 가이드**: 코드 컨벤션, 기여 방법
6. **릴리스 노트**: 버전별 변경 사항
7. **FAQ**: 자주 묻는 질문
8. **트러블슈팅**: 문제 해결 가이드
9. **코드 주석**: 함수/클래스 설명
10. **UML 다이어그램**: 클래스 다이어그램 자동 생성

#### 8.2 API 연동 및 캐싱

**Q82. GitHub API 요청 제한 문제는 어떻게 해결했나요?**
- **문제**: GitHub API는 시간당 60건(비인증) / 5,000건(인증) 제한
- **해결책**:
  1. **인증 토큰 사용**: Personal Access Token으로 5,000건 확보
  2. **캐싱 시스템**: Redis에 저장소 정보 캐싱 (TTL 1시간)
  3. **배치 처리**: 여러 파일을 한 번의 GraphQL 쿼리로 조회
  4. **증분 업데이트**: 변경된 파일만 다시 가져오기
- **결과**: API 요청량 50% 감소, 문서 생성 속도 2배 향상

---

## 공통 면접 질문

### 기술 스택

**Q83. React 19를 선택한 이유는 무엇인가요?**
- **Server Components**: 서버 사이드 렌더링으로 초기 로딩 속도 향상
- **Concurrent Rendering**: 더 부드러운 사용자 경험
- **Automatic Batching**: 상태 업데이트 최적화
- **Improved Hooks**: useTransition, useDeferredValue 등 성능 훅

**Q84. TypeScript를 사용하는 이유는 무엇인가요?**
- **타입 안전성**: 런타임 에러를 컴파일 타임에 방지
- **자동완성**: IDE 지원으로 개발 생산성 향상
- **리팩토링 용이**: 타입 정의로 안전한 코드 변경
- **문서화**: 타입 자체가 코드 문서 역할

**Q85. Supabase vs Firebase 비교**

| 항목 | Supabase | Firebase |
|------|----------|----------|
| 데이터베이스 | PostgreSQL (SQL) | Firestore (NoSQL) |
| 실시간 | Realtime (WebSocket) | Realtime Database |
| 인증 | Supabase Auth | Firebase Auth |
| 스토리지 | Supabase Storage | Firebase Storage |
| 확장성 | pgvector, RLS 등 강력한 기능 | 간단한 설정 |
| 가격 | 무료 플랜 넉넉 | 무료 플랜 제한적 |
| **선택 이유** | SQL 친숙, RLS 보안, pgvector AI | - |

**Q86. AI API 비용 최적화 전략은 무엇인가요?**
1. **캐싱**: Redis로 동일한 요청 결과 재사용 (24시간 TTL)
2. **효율적 모델 선택**: GPT-4o-mini, Claude 3.5 Sonnet 등 저렴한 모델
3. **청킹**: 긴 텍스트를 나눠서 처리
4. **배치 처리**: 여러 요청을 모아서 한 번에 처리
5. **프롬프트 최적화**: 불필요한 설명 제거, 핵심만 요청

**Q87. 실시간 통신을 구현한 방법은 무엇인가요?**
- **WebSocket**: 양방향 실시간 통신 (Trading Intelligence, Sensor Game Hub)
- **Socket.IO**: WebSocket + 폴링 폴백 (Sensor Game Hub)
- **Supabase Realtime**: PostgreSQL 변경 사항 실시간 구독 (Convi)
- **Redis Pub/Sub**: 서버 간 메시지 브로커 (Trading Intelligence)

### 프로젝트 관리

**Q88. 팀 리더로서 가장 중요하게 생각하는 것은 무엇인가요?**
- **명확한 커뮤니케이션**: 목표, 역할, 일정을 투명하게 공유
- **기술적 리더십**: 어려운 문제를 해결하고 팀원을 지원
- **자율성 존중**: 팀원의 의견을 듣고 자율적으로 일할 수 있는 환경 조성
- **지속적 피드백**: 코드 리뷰, 회고를 통해 함께 성장

**Q89. iOS 개발자와 협업 경험을 설명해주세요.**
- **API-First 설계**: 백엔드 API를 먼저 설계하고 Swagger 문서화
- **Swift 코드 예시 제공**: Swagger에 Swift 코드 샘플 포함
- **정기 미팅**: 매주 월요일 API 스펙 회의
- **빠른 피드백**: Postman Collection 공유로 즉시 테스트 가능

**Q90. 개인 프로젝트 vs 팀 프로젝트의 차이는 무엇인가요?**

| 항목 | 개인 프로젝트 | 팀 프로젝트 |
|------|--------------|------------|
| 속도 | 빠른 의사결정 | 합의 필요 |
| 자유도 | 높음 | 제약 있음 |
| 학습 | 모든 영역 경험 | 특정 영역 집중 |
| 협업 | 불필요 | 필수 |
| 책임 | 전적으로 본인 | 분산 |

**개인 프로젝트 장점**: 빠른 실험, 자유로운 기술 선택
**팀 프로젝트 장점**: 협업 능력 향상, 다양한 관점 획득

**Q91. 바이브 코딩(Vibe Coding) 도구 활용 경험은?**
- **Claude Code**: AI와 대화하며 코드 작성, 리팩토링
- **Cursor**: AI 기반 코드 완성, 버그 수정
- **GitHub Copilot**: 코드 자동 완성
- **활용 효과**:
  - 개발 속도 2~3배 향상
  - 반복 작업 자동화 (CRUD, 테스트 코드 등)
  - 빠른 프로토타이핑 및 아이디어 검증
  - 창의적 문제 해결에 집중 가능

### 문제 해결

**Q92. 가장 어려웠던 기술적 도전은 무엇이었나요?**

**[Sensor Game Hub] AI 생성 코드의 품질 보장**

- **상황**: AI가 생성한 게임 코드가 때때로 문법 오류 포함
- **문제**: 사용자에게 에러가 노출되면 신뢰도 하락
- **해결**:
  1. 코드 검증 시스템: AST 파싱으로 문법 오류 자동 검사
  2. 샌드박스 실행: iframe에서 먼저 테스트 후 배포
  3. 에러 자동 수정: 에러 발생 시 AI에게 에러 로그 전달하여 재생성
- **결과**: 에러율 80% 감소, 사용자 만족도 향상

**Q93. 트러블슈팅 사례를 STAR 기법으로 설명해주세요.**

**[Trading Intelligence] WebSocket 연결 불안정 문제**

- **Situation (상황)**: 실시간 주가 스트리밍 중 연결이 자주 끊김
- **Task (과제)**: 안정적인 실시간 데이터 전송 보장
- **Action (행동)**:
  1. Heartbeat 시스템 구축: 10초마다 ping/pong 확인
  2. 재연결 로직: Exponential Backoff 전략으로 재시도
  3. Redis Pub/Sub 도입: 서버 간 메시지 브로커로 장애 격리
- **Result (결과)**: 연결 안정성 99.9% 달성, 사용자 이탈률 감소

**Q94. 성능 최적화 사례를 설명해주세요.**

**[Synapse AI] 벡터 검색 성능 최적화**

- **문제**: 10,000개 문서에서 검색 시 5초 이상 소요
- **해결**:
  1. HNSW 인덱스 생성: O(log n) 검색 속도
  2. 하이브리드 검색: 키워드 필터링 후 벡터 검색
  3. 캐싱: 자주 검색되는 쿼리 결과를 Redis에 저장
- **결과**: 검색 속도 0.5초로 10배 향상

**Q95. 보안 관련 고려사항은 무엇인가요?**
- **RLS (Row Level Security)**: Supabase에서 사용자별 데이터 접근 제어
- **JWT 토큰**: 인증/인가 시스템 구축
- **입력 검증**: SQL Injection, XSS 공격 방지
- **HTTPS**: 모든 통신 암호화
- **환경 변수**: API 키, 비밀번호 등을 환경 변수로 관리

### 커리어 및 성장

**Q96. 개발자로서의 강점은 무엇인가요?**
1. **AI 서비스 개발 전문성**: OpenAI, Anthropic API 활용 경험 풍부
2. **풀스택 능력**: React부터 Node.js, Python까지 전 영역 개발 가능
3. **문제 해결 능력**: 복잡한 기술 문제를 분석하고 창의적으로 해결
4. **빠른 학습**: 새로운 기술을 빠르게 습득하고 프로젝트에 적용
5. **프로덕션 경험**: 모든 프로젝트가 실제 배포되어 운영 중

**Q97. 향후 학습 계획은 무엇인가요?**
- **단기 (3개월)**:
  - Kubernetes, Docker 학습으로 컨테이너 오케스트레이션 능력 향상
  - GraphQL 마스터하여 효율적 API 설계
  - AI 프롬프트 엔지니어링 심화 학습
- **중기 (6개월)**:
  - Rust 학습으로 시스템 프로그래밍 능력 확보
  - 대규모 트래픽 처리 경험 쌓기
  - 오픈소스 프로젝트 기여
- **장기 (1년)**:
  - AI 엔지니어로서의 전문성 심화 (LLM Fine-tuning, RAG 고도화)
  - 테크 리드/아키텍트 역할 수행

**Q98. 희망하는 개발 방향은 무엇인가요?**
- **AI 엔지니어**: LLM을 활용한 혁신적인 서비스 개발
- **풀스택 개발자**: 프론트엔드부터 백엔드, 인프라까지 전 영역 담당
- **테크 리드**: 기술적 의사결정을 주도하고 팀을 이끄는 역할

**Q99. 우리 회사에 기여할 수 있는 점은 무엇인가요?**
1. **AI 서비스 개발 경험**: OpenAI, Anthropic API를 활용한 실전 프로젝트 8개
2. **빠른 프로토타이핑**: 바이브 코딩 도구로 아이디어를 빠르게 검증
3. **엔터프라이즈급 아키텍처**: 확장 가능한 시스템 설계 경험
4. **프로덕션 운영 경험**: 실제 서비스를 배포하고 운영한 경험
5. **협업 능력**: iOS 개발자와의 협업 경험, 팀 리더 경험

**Q100. 마지막으로 하고 싶은 말씀은?**
저는 AI와 웹 기술을 결합하여 사용자에게 실질적인 가치를 제공하는 개발자입니다.
8개의 프로젝트를 모두 프로덕션 레벨로 완성하며, 단순히 코드를 작성하는 것이 아닌,
실제 사용자의 문제를 해결하는 서비스를 만드는 것에 집중해왔습니다.

특히 Sensor Game Hub에서는 Claude Sonnet 4.5 1M Token을 활용한 AI 게임 생성 시스템을,
Synapse AI에서는 pgvector 기반 지능형 지식 관리 시스템을,
Trading Intelligence에서는 마이크로서비스 아키텍처 기반 실시간 주식 분석 플랫폼을 구축하며,
최신 기술을 실전에 적용하는 능력을 검증받았습니다.

저의 강점인 AI 서비스 개발 전문성과 풀스택 능력, 그리고 프로덕션 운영 경험을 바탕으로
귀사의 성장에 기여하고 싶습니다. 감사합니다.

---

## STAR 기법 답변 예시

### 예시 1: 문제 해결 능력

**질문**: "프로젝트에서 겪은 가장 큰 기술적 도전과 해결 과정을 설명해주세요."

**답변**:

**Situation (상황)**:
Sensor Game Hub 프로젝트에서 AI가 생성한 게임 코드에 종종 문법 오류나 런타임 에러가 포함되어 사용자 경험을 해치는 문제가 발생했습니다. 사용자가 AI와 대화하여 게임을 생성했지만, 실행 시 에러가 나면 신뢰도가 크게 떨어지는 상황이었습니다.

**Task (과제)**:
AI 생성 코드의 품질을 보장하고, 에러 발생 시 자동으로 수정하는 시스템을 구축하여 사용자에게 안정적인 게임 경험을 제공해야 했습니다.

**Action (행동)**:
1. **코드 검증 시스템 구축**: TypeScript AST 파서를 사용하여 AI가 생성한 코드를 자동으로 분석하고, 문법 오류를 사전에 감지하는 시스템을 만들었습니다.
2. **샌드박스 환경 구축**: iframe을 활용하여 게임을 격리된 환경에서 먼저 실행하고, 에러가 발생하면 메인 앱에 영향을 주지 않도록 했습니다.
3. **에러 자동 수정 시스템**: 런타임 에러가 발생하면 에러 로그와 함께 AI에게 다시 전달하여 수정된 코드를 생성하도록 자동화했습니다.
4. **구체적 프롬프트 전략**: AI에게 "반드시 웹 표준을 준수하라", "모바일 센서 API만 사용하라" 등 명확한 제약 조건을 명시하여 코드 품질을 향상시켰습니다.

**Result (결과)**:
- 에러 발생률 80% 감소
- 사용자 만족도 크게 향상 (피드백: "안정적이고 신뢰할 수 있다")
- 게임 생성 성공률 95% 달성
- AI 기반 자동 수정 덕분에 수동 개입 불필요

**학습한 점**:
AI 생성 코드를 실전에 사용할 때는 반드시 검증 시스템이 필요하며, 명확한 프롬프트 설계가 코드 품질을 좌우한다는 것을 배웠습니다.

---

### 예시 2: 협업 능력

**질문**: "팀 프로젝트에서 의견 충돌이 있었던 경험과 해결 과정을 설명해주세요."

**답변**:

**Situation (상황)**:
Sensor Game Hub 프로젝트에서 팀원 간 Git 브랜치 전략에 대한 의견 충돌이 있었습니다. 한 팀원은 Feature Branch 전략을, 다른 팀원은 Git Flow를 선호했고, 이로 인해 코드 충돌이 자주 발생했습니다.

**Task (과제)**:
팀원 간 합의를 이끌어내고, 코드 충돌을 최소화할 수 있는 명확한 브랜치 전략을 수립해야 했습니다.

**Action (행동)**:
1. **팀 미팅 소집**: 모든 팀원이 참여하는 미팅을 열어 각자의 의견을 듣고, 장단점을 분석했습니다.
2. **데이터 기반 의사결정**: 실제로 발생한 코드 충돌 사례를 분석하여, Git Flow가 더 적합하다는 객관적 근거를 제시했습니다.
3. **합의 도출**: Git Flow를 채택하되, 복잡한 규칙은 간소화하여 팀원들이 쉽게 따를 수 있도록 조정했습니다.
4. **문서화**: Git Flow 가이드를 작성하여 Notion에 공유하고, 매주 회고에서 개선점을 논의했습니다.

**Result (결과)**:
- 코드 충돌 발생률 70% 감소
- 팀원 간 협업 효율 향상
- 명확한 브랜치 전략 덕분에 신규 팀원 온보딩 시간 단축

**학습한 점**:
기술적 의사결정은 개인의 선호가 아닌 객관적 데이터와 팀의 합의를 바탕으로 이루어져야 하며, 문서화와 지속적인 피드백이 중요하다는 것을 배웠습니다.

---

### 예시 3: 성과 중심

**질문**: "가장 자랑스러운 프로젝트와 그 성과를 설명해주세요."

**답변**:

**Situation (상황)**:
Trading Intelligence 프로젝트를 시작할 때, 시니어 투자자들이 복잡한 주식 분석 도구를 사용하기 어려워하는 문제를 발견했습니다. 실시간 정보는 부족하고, AI 분석은 비싸며, UI는 복잡했습니다.

**Task (과제)**:
시니어 투자자를 위한 실시간 AI 주식 분석 플랫폼을 구축하여, 누구나 쉽게 사용할 수 있는 서비스를 만들어야 했습니다.

**Action (행동)**:
1. **마이크로서비스 아키텍처**: 6개 독립 서비스로 분리하여 확장 가능하고 안정적인 시스템 구축
2. **AI 오케스트레이션**: Claude AI(메인) + OpenAI(폴백) 이중화 시스템으로 AI 분석 비용 50% 절감
3. **실시간 시스템**: WebSocket + Redis Pub/Sub로 1초 단위 주가 갱신 구현
4. **시니어 접근성 특화**: 큰 폰트(18px+), 고대비 모드, TTS 음성 알림 지원

**Result (결과)**:
- 엔터프라이즈급 마이크로서비스 아키텍처 완성 (6개 서비스)
- AI 분석 비용 50% 절감 (Claude + OpenAI 오케스트레이션)
- 실시간 시스템 안정성 99.9% 달성
- 시니어 사용자 접근성 크게 향상 (피드백: "처음으로 주식 앱을 쉽게 사용할 수 있었다")

**학습한 점**:
사용자 중심 설계의 중요성을 깊이 깨달았으며, 복잡한 기술을 단순하고 직관적인 UX로 전달하는 것이 개발자의 역할이라는 것을 배웠습니다.

---

### 예시 4: 학습 능력

**질문**: "새로운 기술을 빠르게 학습하고 적용한 경험을 설명해주세요."

**답변**:

**Situation (상황)**:
Synapse AI 프로젝트를 시작할 때, PDF 파싱과 벡터 검색 기술에 대한 경험이 전혀 없었습니다. 하지만 지능형 지식 관리 시스템을 구축하기 위해서는 필수적인 기술이었습니다.

**Task (과제)**:
2주 내에 PDF 처리, pgvector, 임베딩 모델 등 생소한 기술을 학습하고, 실제 프로덕션 레벨 시스템을 구축해야 했습니다.

**Action (행동)**:
1. **공식 문서 집중 학습**: Supabase, pgvector, OpenAI 공식 문서를 꼼꼼히 읽고, 튜토리얼을 따라 실습
2. **작은 프로토타입 제작**: 각 기술을 독립적으로 테스트하는 작은 프로젝트를 만들어 이해도 향상
3. **오픈소스 분석**: GitHub에서 유사한 프로젝트를 찾아 코드를 분석하고 베스트 프랙티스 학습
4. **문제 해결 커뮤니티 활용**: Stack Overflow, Supabase Discord에서 질문하고 답변 받음

**Result (결과)**:
- 2주 만에 PDF 처리 시스템 구축 완료
- pgvector 기반 벡터 검색 시스템 구현 (검색 정확도 92%)
- Supabase Edge Functions를 활용한 서버사이드 아키텍처 완성
- 프로젝트 배포 후 안정적으로 운영 중

**학습한 점**:
공식 문서를 꼼꼼히 읽고, 작은 프로토타입을 만들어보는 것이 새로운 기술을 빠르게 습득하는 가장 효과적인 방법이라는 것을 배웠습니다.

---

### 예시 5: 리더십

**질문**: "팀 리더로서 팀원의 성장을 도운 경험을 설명해주세요."

**답변**:

**Situation (상황)**:
Sensor Game Hub 프로젝트에서 팀 리더를 맡았을 때, 한 팀원이 React Hooks에 대한 이해도가 낮아 컴포넌트 개발에 어려움을 겪고 있었습니다.

**Task (과제)**:
팀원의 React Hooks 이해도를 높여 독립적으로 컴포넌트를 개발할 수 있도록 지원해야 했습니다.

**Action (행동)**:
1. **1:1 페어 프로그래밍**: 매주 2시간씩 페어 프로그래밍 세션을 진행하며, useState, useEffect, useContext 등을 함께 실습
2. **코드 리뷰 강화**: 팀원의 PR에 상세한 피드백을 남기고, 개선 방향을 제시
3. **학습 자료 큐레이션**: React 공식 문서, 좋은 튜토리얼, 예제 코드를 공유
4. **작은 성공 경험**: 간단한 컴포넌트부터 시작하여 점차 복잡한 기능을 맡도록 단계적으로 난이도 조절

**Result (결과)**:
- 2주 만에 팀원이 독립적으로 컴포넌트 개발 가능
- 팀원의 코드 품질 향상 (코드 리뷰 피드백 개수 50% 감소)
- 팀원의 자신감 상승 (피드백: "이제 React가 재미있어졌다")
- 팀 전체 개발 속도 향상

**학습한 점**:
좋은 리더는 팀원에게 답을 알려주는 것이 아니라, 스스로 배우고 성장할 수 있는 환경을 만들어주는 사람이라는 것을 배웠습니다.

---

## 마무리

이 문서는 조민혁의 포트폴리오 8개 프로젝트를 기반으로 작성된 **면접 예상 질문 및 답변 가이드**입니다.

### 활용 방법
1. **프로젝트별 질문 숙지**: 각 프로젝트의 기술적 세부사항을 정확히 이해
2. **STAR 기법 연습**: 주요 질문에 대해 STAR 기법으로 답변 준비
3. **공통 질문 대비**: 기술 스택, 협업, 커리어 등 일반적 질문에 대한 답변 준비
4. **모의 면접**: 친구나 동료와 함께 모의 면접 진행

### 추가 준비 사항
- 포트폴리오 사이트 URL 숙지: https://minhyuk.kr
- GitHub 프로필 정리
- LinkedIn 프로필 업데이트
- 기술 블로그 작성 (선택 사항)

**면접에서 좋은 결과 있기를 바랍니다! 화이팅! 💪**
